{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción a la MasterClass de Python\n",
    "\n",
    "¡Bienvenidos! En esta MasterClass exploraremos cómo Python puede ser una herramienta poderosa y versátil para realizar consultas y análisis sobre un dataset de testimonios en el marco de la **Unidad de Búsqueda de Personas Dadas por Desaparecidas (UBPD)**. La idea central de esta sesión es comprender cómo aprovechar el potencial de Python para extraer información clave, procesar datos textuales y generar resultados útiles en el contexto de investigaciones complejas.\n",
    "\n",
    "Los testimonios que analizaremos están estructurados en un **dataset de relatos sintéticos**, que simula los tipos de datos y narrativas que podrían encontrarse en un entorno real de trabajo en la UBPD. A lo largo de esta MasterClass, trabajaremos en los siguientes aspectos:\n",
    "\n",
    "- **Comprensión y exploración del dataset**: Veremos cómo iniciar una exploración detallada del dataset, obteniendo una visión general de los datos y preparando el contenido para consultas más avanzadas.\n",
    "- **Consultas y filtrado de información**: Python nos permitirá realizar búsquedas específicas en los testimonios, identificando rápidamente aquellos relatos que contienen palabras clave de interés o que responden a ciertas categorías.\n",
    "- **Extracción de patrones y visualización**: Exploraremos cómo analizar patrones en el texto y visualizar los resultados para obtener una interpretación más profunda de los datos.\n",
    "- **Reconocimiento de entidades**: En una sección avanzada, implementaremos un modelo de Reconocimiento de Entidades Nombradas (NER), que puede ayudarnos a identificar personas, lugares y eventos mencionados en los testimonios.\n",
    "\n",
    "Python será nuestro aliado para demostrar cómo un análisis bien estructurado puede generar **insights valiosos**, ofreciendo una base sólida para la toma de decisiones informada en contextos sensibles y críticos como el de la UBPD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objetivo**: Explorar el uso de Python para realizar consultas y análisis en un dataset de testimonios en el contexto de la UBPD.\n",
    "\n",
    "**Dataset**: El dataset de relatos sintéticos se encuentra en el archivo `dataset-testimonios-sinteticos.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las librerías necesarias\n",
    "import pandas as pd\n",
    "\n",
    "# Cargamos el dataset\n",
    "data = pd.read_csv('../datos/dataset_testimonios_sinteticos.csv')\n",
    "\n",
    "# Exploramos las primeras filas del dataset\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observaciones Iniciales sobre los Datos\n",
    "\n",
    "1. **Columnas Presentes**: El dataset contiene 6 columnas:\n",
    "   - `id`: Identificador único.\n",
    "   - `nombre`: Nombre del testigo.\n",
    "   - `cedula`: Número de cédula del testigo.\n",
    "   - `ciudad`: Ciudad de residencia o donde ocurrió el evento.\n",
    "   - `categoria`: Clasificación del tipo de testimonio (por ejemplo, \"Desaparición forzada\", \"Minas antipersona\").\n",
    "   - `testimonio`: Texto del relato del testigo.\n",
    "\n",
    "2. **Tipos de Datos**:\n",
    "   - Dos columnas (`id` y `cedula`) son de tipo `int64`, mientras que las demás son de tipo `object` (texto).\n",
    "   - La columna `cedula` podría contener valores que se consideran identificadores, pero analizar su validez puede ser relevante para asegurarse de que no existan datos duplicados.\n",
    "\n",
    "3. **Valores Faltantes**:\n",
    "   - No se encontraron valores faltantes en ninguna columna, lo cual facilita el análisis inicial, pero es importante verificar posibles inconsistencias en los datos.\n",
    "\n",
    "4. **Distribución de Datos Numéricos**:\n",
    "   - La columna `cedula` tiene un amplio rango de valores, lo que sugiere que corresponde a una serie de números de identificación únicos.\n",
    "   - No hay estadísticas descriptivas relevantes para las columnas de tipo `object` en esta exploración inicial, pero esto se puede complementar con otras herramientas.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descripción del dataset\n",
    "\n",
    "La descripción general del datset se puede hacer de la siguiente forma:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descripción general de los datos\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumen estadístico (si es relevante para algunas columnas numéricas)\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizamos valores nulos\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preguntas para Guiar el Análisis y Uso de Herramientas de Pandas\n",
    "\n",
    "1. **¿Cuántas categorías únicas existen en el campo `categoria` y cuáles son las más frecuentes?**\n",
    "   - Esto invita a usar `value_counts` para comprender mejor la distribución de los tipos de testimonios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pregunta 1: ¿Cuántas categorías únicas existen en el campo `categoria` y cuáles son las más frecuentes?\n",
    "categoria_counts = data['categoria'].value_counts()\n",
    "print(\"Distribución de las categorías:\")\n",
    "print(categoria_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **¿Existen ciudades que aparezcan con mayor frecuencia y cuál es su distribución?**\n",
    "   - Usar `groupby` y `value_counts` para analizar la concentración de testimonios en ciertas ciudades puede ayudar a entender patrones geográficos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pregunta 2: ¿Existen ciudades que aparezcan con mayor frecuencia y cuál es su distribución?\n",
    "ciudad_counts = data['ciudad'].value_counts()\n",
    "print(\"\\nDistribución de testimonios por ciudad:\")\n",
    "print(ciudad_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **¿Es posible que algunos valores de `cedula` estén duplicados o presenten inconsistencias?**\n",
    "   - Aplicar `duplicated` en la columna `cedula` ayuda a identificar posibles entradas duplicadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pregunta 3: ¿Es posible que algunos valores de `cedula` estén duplicados o presenten inconsistencias?\n",
    "cedula_duplicates = data['cedula'].duplicated().sum()\n",
    "print(\"\\nNúmero de cédulas duplicadas:\", cedula_duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **¿Cuáles son las palabras más comunes en los testimonios?**\n",
    "   - Utilizar `apply` en combinación con una función personalizada para tokenizar y contar palabras comunes en los textos podría ser un análisis interesante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Una función en python ¿Qué hacen?\n",
    "## Las funciones en Python son bloques de código que se pueden reutilizar en diferentes partes de un programa.\n",
    "\n",
    "## Ejemplo\n",
    "\n",
    "def texto_en_mayusculas(texto):\n",
    "    return texto.upper()\n",
    "\n",
    "texto = \"Hola Mundo!\"\n",
    "\n",
    "texto_en_mayusculas(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Aplicar la función a una columna de un DataFrame\n",
    "\n",
    "data['categoria_mayusculas'] = data['categoria'].apply(texto_en_mayusculas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### También hay funciones de paquetes, por ejemplo Counter\n",
    "### O metodos de las clases, por ejemplo split\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "texto_ejemplo = \"\"\"En el monte de la china, una china se perdió y como yo era un perdido nos encontramos los dos\"\"\"\n",
    "\n",
    "palabras = texto_ejemplo.split()\n",
    "\n",
    "contador_palabras = Counter(palabras)\n",
    "\n",
    "print(contador_palabras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "# Pregunta 4: ¿Cuáles son las palabras más comunes en los testimonios?\n",
    "# Concatenamos todos los testimonios en una sola cadena de texto\n",
    "all_text = ' '.join(data['testimonio'].dropna().values)\n",
    "# Tokenizamos y contamos la frecuencia de cada palabra\n",
    "word_counts = Counter(all_text.lower().split())\n",
    "most_common_words = word_counts.most_common(10)\n",
    "print(\"\\nPalabras más comunes en los testimonios:\")\n",
    "for word, freq in most_common_words:\n",
    "    print(f\"{word}: {freq}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. **¿Existen testimonios de longitud considerablemente mayor o menor que otros?**\n",
    "   - Esto sugiere usar `apply(len)` en la columna `testimonio` y visualizar la longitud promedio y su dispersión, ayudando a identificar testimonios que podrían requerir una revisión adicional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['testimonio_length'] = data['testimonio'].apply(len)\n",
    "testimonio_length_stats = data['testimonio_length'].describe()\n",
    "print(\"\\nEstadísticas de longitud de los testimonios:\")\n",
    "print(testimonio_length_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preguntas rápidas que se solucionan con pandas\n",
    "\n",
    "*¿Búsqueda de cédulas específicas en el dataset usando pandas?*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos la cédula que queremos buscar\n",
    "cedula_buscada = 2615872530\n",
    "\n",
    "# Filtramos el dataset para encontrar la fila correspondiente\n",
    "resultado_cedula = data[data['cedula'] == cedula_buscada]\n",
    "resultado_cedula\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*¿Cómo filtrar testimonios por una categoría específica, como \"Desaparición forzada\"?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos la categoría que queremos buscar\n",
    "categoria_buscada = \"Desaparición forzada\"\n",
    "\n",
    "# Filtramos el dataset para mostrar solo los testimonios en esa categoría\n",
    "resultado_categoria = data[data['categoria'] == categoria_buscada]\n",
    "resultado_categoria[['nombre', 'ciudad', 'testimonio']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*¿Búsqueda de todos los testimonios relacionados con una palabra clave, como \"violencia\"?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos la palabra clave a buscar\n",
    "palabra_clave = \"violencia\"\n",
    "\n",
    "# Filtramos el dataset para buscar la palabra en la columna de testimonios\n",
    "resultado_palabra = data[data['testimonio'].str.contains(palabra_clave, case=False, na=False)]\n",
    "resultado_palabra[['nombre', 'categoria', 'testimonio']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*¿Cuántos testimonios corresponden a cada ciudad?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contamos la cantidad de testimonios por ciudad\n",
    "testimonios_por_ciudad = data['ciudad'].value_counts()\n",
    "testimonios_por_ciudad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*¿Cuáles son las categorías más frecuentes y cuántos testimonios tiene cada una?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contamos la cantidad de testimonios en cada categoría\n",
    "testimonios_por_categoria = data['categoria'].value_counts()\n",
    "testimonios_por_categoria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*¿Cómo buscar todos los testimonios de una ciudad específica, como \"Bogotá\"?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos la ciudad que queremos buscar\n",
    "ciudad_buscada = \"Bogotá\"\n",
    "\n",
    "# Filtramos el dataset para mostrar los testimonios de esa ciudad\n",
    "resultado_ciudad = data[data['ciudad'] == ciudad_buscada]\n",
    "resultado_ciudad[['nombre', 'categoria', 'testimonio']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*¿Cómo encontrar los nombres de los testigos que aparecen más de una vez en el dataset?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contamos las ocurrencias de cada nombre y mostramos los que aparecen más de una vez\n",
    "testigos_duplicados = data['nombre'].value_counts()\n",
    "testigos_duplicados[testigos_duplicados > 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tratamiento de Datos Textuales\n",
    "\n",
    "El tratamiento de datos textuales es un aspecto clave en el análisis de testimonios, ya que permite extraer información relevante y descubrir patrones ocultos en el texto. Algunas técnicas comunes para el procesamiento de datos textuales incluyen:\n",
    "\n",
    "- **Convertir a minúsculas**: Para asegurar la consistencia en el análisis y evitar problemas de distinción entre mayúsculas y minúsculas.\n",
    "- **Eliminar caracteres especiales**: Para limpiar el texto y facilitar la tokenización.\n",
    "- **Remover números**: Si los números no son relevantes para el análisis, es común eliminarlos para centrarse en el contenido textual.\n",
    "- **Tokenización**: Dividir el texto en palabras o tokens\n",
    "- **Filtrado de stopwords**: Eliminar palabras comunes que no aportan información relevante al análisis.\n",
    "- **Stemming o lematización**: Reducir las palabras a su raíz o forma base para simplificar el análisis y mejorar la precisión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*¿Cómo convertir el texto a minúsculas para una mayor consistencia?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos todos los textos de la columna 'testimonio' a minúsculas\n",
    "data['testimonio_limpio'] = data['testimonio'].str.lower()\n",
    "data[['testimonio', 'testimonio_limpio']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*¿Cómo eliminar caracteres especiales y puntuación en los testimonios?*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Eliminamos caracteres especiales, dejando solo letras y espacios\n",
    "data['testimonio_limpio'] = data['testimonio_limpio'].apply(lambda x: re.sub(r'\\W+', ' ', str(x)))\n",
    "data[['testimonio', 'testimonio_limpio']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*¿Cómo remover números que no aportan valor semántico en el texto?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos números de los testimonios\n",
    "data['testimonio_limpio'] = data['testimonio_limpio'].apply(lambda x: re.sub(r'\\d+', '', x))\n",
    "data[['testimonio', 'testimonio_limpio']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*¿Cómo eliminar espacios extras que puedan haber quedado tras la limpieza?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos espacios en exceso al inicio, final y entre palabras\n",
    "data['testimonio_limpio'] = data['testimonio_limpio'].str.strip()\n",
    "data['testimonio_limpio'] = data['testimonio_limpio'].replace(r'\\s+', ' ', regex=True)\n",
    "data[['testimonio', 'testimonio_limpio']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*¿Cómo remover stopwords en español (palabras comunes sin relevancia)?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Aseguramos la descarga de las stopwords en español\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('spanish'))\n",
    "\n",
    "# Eliminamos las stopwords\n",
    "data['testimonio_limpio'] = data['testimonio_limpio'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n",
    "data[['testimonio', 'testimonio_limpio']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*¿Cómo aplicar stemming para reducir las palabras a sus raíces?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "# Inicializamos el stemmer en español\n",
    "stemmer = SnowballStemmer('spanish')\n",
    "\n",
    "# Aplicamos stemming a cada palabra del texto\n",
    "data['testimonio_limpio'] = data['testimonio_limpio'].apply(lambda x: ' '.join([stemmer.stem(word) for word in x.split()]))\n",
    "data[['testimonio', 'testimonio_limpio']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*¿Cómo combinar todos los pasos anteriores en una sola función de limpieza?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos una función completa para limpiar el texto\n",
    "def limpiar_texto(texto):\n",
    "    texto = texto.lower()  # Convertir a minúsculas\n",
    "    texto = re.sub(r'\\W+', ' ', texto)  # Eliminar caracteres especiales\n",
    "    texto = re.sub(r'\\d+', '', texto)  # Eliminar números\n",
    "    texto = texto.strip()  # Eliminar espacios al inicio y final\n",
    "    texto = ' '.join([word for word in texto.split() if word not in stop_words])  # Eliminar stopwords\n",
    "    texto = ' '.join([stemmer.stem(word) for word in texto.split()])  # Aplicar stemming\n",
    "    return texto\n",
    "\n",
    "# Aplicamos la función a la columna 'testimonio'\n",
    "data['testimonio_limpio'] = data['testimonio'].apply(limpiar_texto)\n",
    "data[['testimonio', 'testimonio_limpio']].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capacitacion_ubpd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
